# RUN SECTION e.g. for EMCEE, DE+EMCEE, etc.
run:
    full_path: .
    sub_folder: test_emcee
    seed: 42
    mass_type: e
    delta_sigma: 1.0e-4
    #emcee_previous: False
    trades_previous: None #/full/path/to/run/trades/finalXpar.dat
    nthreads: 34
    pyde:
        type: run # False/no, run, resume, to_emcee
        # population size == number of different configurations for each iteration of the DE
        npop: 68 # if it matches nwalkers is better
        # generation size == number of iterations
        ngen: 42000
        # saving steps == number of steps for the save points ==> it creates a de_run.hdf5 file
        save: 4200 
        # Difference amplification factor. Values between 0.5-0.8 are good in most cases.
        f: 0.5
        # Cross-over probability. Use 0.9 to test for fast convergence, and smaller values (~0.1) for a more elaborate search.
        c: 0.5
        # maximize == True: maximize the function, maximize == False: minimize the function
        maximize: True
    emcee:
        nwalkers: 68
        nruns: 2000
        thin_by: 100 # !! the true nruns will be nruns x thin_by, this is also the keyword used by emcee and it will keep only thin_by steps
        emcee_restart: False
        emcee_progress: True
        pre_optimise: True
        move:
            type: ["de", "desnooker"]
            fraction: [0.8, 0.2]
            # type: ["ai"]
            # fraction: [1.0]
        #where ai == affine invariant, de == differential evolution, desnooker==de with different implementation
    # ultranest:
    #     live_points: 400
    #     resume_flag: "resume"
    #     dlogz: 0.5
    # dynesty:
    #     live_points: 500
    #     bound: "multi" # none, single, balls, cubes
    #     sample: "auto"
    #     restore: False
    #     dlogz: None
    #     pfrac: 0.8
# ANALYSIS SECTION, TO RUN AFTER EMCEE SAVED AT LEAST ONE SAVE POINT, YOU CAN RUN IT ALSO FOR DE/PSO OUTPUT
analysis:
    full_path: ./test_emcee
    m_type: "e" # suggested: j, e, n
    nburnin: 100 # number of steps to discard as burn-in
    emcee_old_save: False # True
    temp_status: False # True if you are analysing a temporary emcee run
    use_thin: 1 # remember if you used thin_by > 1 or not
    seed: 42
    from_file: None # trades file of a simulation output to simulate and plot. Default = None.
    n_samples: 42 # set to 0 if you don't want to simulate and save samples --> samples_ttra_rv.hdf5
    overplot: map_hdi # initial, pso, de, median, map_hdi, map, mode, adhoc
    corner_type: pygtc # pygtc, custom, both
    lnProb_selection: [None, None] # further selection on ln-probability, default [None, None] = [-np.inf, np.inf]
    all_analysis: True # if set to False you should set by hand the following arguments, otherwise it run all of them
    save_posterior: True
    save_parameters: True
    chain: True
    gelman_rubin: True
    gr_steps: 10
    geweke: True
    gk_steps: 10
    correlation_fitted: True
    correlation_physical: True
# O-C PLOTS, if missing the SECTION NO PLOT AT ALL
OC:
    plot_oc: True
    full_path: ./test_emcee
    sim_name: ["de", "initial", "median", "map_hdi", "map"] # list of [initial, pso, de, median, map_hdi, map, mode, from_file]
    # full_sim_path: "./0668_sim_map_hdi" # one of the folder created by analysis/save_parameters in the form XXXX_sim_TYPE
    # sim_id: 668 # the first number of the above parameter name
    idplanet_name: {} # e.g {2: "b", 3: "c"}
    lmflag: 0 # if LM has been run (1) or not (0). Default 0.0
    tscale: None # time scale to remove from x-axis plot, if float it will be written in xlabel as ".0f",
                 # suggested: [value, ".Xf"] where X is the number of digits to display, Default None means removing nothing, like [0.0, ".0f"].
    plot_title: True # True or False
    unit: "auto" # unit of the O-C, if "auto" it auto-detect best unit for each body, otherwise set to: "d", "h", "m", "s".
    samples_file: None # hdf5 file name with samples created by analysis/n_samples > 0: i.e. samples_ttra_rv.hdf5
    plot_obs_sim: False # plot simulations point corrisponding to observations? True/False. Default=True.
    plot_samples: "ci" # how to plot samples: "ci" == "sigma", or "all". "all" will plot each samples
    limits: "obs" # x-y limits based on observations (obs) or samples (sam)
    kep_ele: False # plot of Keplerian Elements of each transiting body during transits
    legend: "in" # in or out, everything else means no legend
    linear_ephemeris: None # default None. It means it will compute the linear ephemeris from data for each body.
                      # Otherwise provide linear ephemeris for one or more bodies (! 2 is the number that identifies the first planet !) as:
        # 2:
        #     Tref: [val, err]
        #     Pref: [val, err]
        # 3: 
        #     Tref: [val, err]
        #     Pref: [val, err]
    idsource_name: None # e.g {1: TESS, 2: CHEOPS} to map sub-data set with telescope -> different color and marker for each data-set
    color_map: "nipy_spectral" # or as {1: "C0", 2: "C1"} the 1, 2, etc match the 1, 2 in idsource_id in NBX_observations.dat

RV:
    plot_rv: True
    full_path: ./test_emcee
    sim_name: ["de", "initial", "median", "map_hdi", "map"] # list of [initial, pso, de, median, map_hdi, map, mode, from_file]
    lmflag: 0 # if LM has been run (1) or not (0). Default 0.0
    tscale: None # time scale to remove from x-axis plot, if float it will be written in xlabel as ".0f",
                 # suggested: [value, ".Xf"] where X is the number of digits to display, Default None means removing nothing, like [0.0, ".0f"].
    plot_title: True # True or False
    samples_file: None # hdf5 file name with samples created by analysis/n_samples > 0: i.e. samples_ttra_rv.hdf5
    limits: "obs" # x-y limits based on observations (obs) or samples (sam)
    legend: "in" # in or out, everything else means no legend
    labels: ["RVdataset#1", "RVdataset#2"] # list or string of labels of different RV dataset (order has to match the numbering of obsRV.dat file)
                                           # or dictionary: {1: "RVdataset#1", 2: "RVdataset#2"}
    color_map: "nipy_spectral" # color map name, color name or {1: color1, 2: color2, etc} where 1, 2, etc match 1,2, in labels
